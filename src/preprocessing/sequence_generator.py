"""
LSTMì„ ìœ„í•œ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±

í˜‘ì—… í¬ì¸íŠ¸:
- ML ì—”ì§€ë‹ˆì–´: ì´ ëª¨ë“ˆë¡œ í•™ìŠµ ë°ì´í„° ìƒì„±
- ë°±ì—”ë“œ: ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œ ìµœê·¼ 60ì¼ ë°ì´í„°ë¥¼ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
"""
import numpy as np
import pandas as pd
from typing import Tuple, List
from sklearn.preprocessing import MinMaxScaler
import pickle
import os


class SequenceGenerator:
    """
    ì‹œê³„ì—´ ë°ì´í„°ë¥¼ LSTM ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
    
    í•µì‹¬ ê°œë…:
    1. Sliding Window: ê³¼ê±° Nì¼ â†’ ë¯¸ë˜ 1ì¼ ì˜ˆì¸¡
    2. Normalization: 0~1 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§ (LSTM í•™ìŠµ íš¨ìœ¨ UP)
    3. Train/Val Split: ì‹œê³„ì—´ì€ ì…”í”Œ ê¸ˆì§€! ìˆœì„œ ìœ ì§€
    """
    
    def __init__(
        self,
        sequence_length: int = 60,
        target_column: str = 'Close',
        feature_columns: List[str] = None
    ):
        """
        Args:
            sequence_length: ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ (ê³¼ê±° ëª‡ ì¼?)
            target_column: ì˜ˆì¸¡í•  íƒ€ê²Ÿ (ë³´í†µ 'Close')
            feature_columns: ì‚¬ìš©í•  Featureë“¤ (Noneì´ë©´ ì „ë¶€ ì‚¬ìš©)
        """
        self.sequence_length = sequence_length
        self.target_column = target_column
        self.feature_columns = feature_columns
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        
    def prepare_data(
        self,
        df: pd.DataFrame,
        validation_split: float = 0.2
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """
        ë°ì´í„° ì „ì²˜ë¦¬ ë° ì‹œí€€ìŠ¤ ìƒì„±
        
        í”„ë¡œì„¸ìŠ¤:
        1. Feature ì„ íƒ
        2. ê²°ì¸¡ì¹˜ ì œê±°
        3. ì •ê·œí™” (MinMaxScaler)
        4. ì‹œí€€ìŠ¤ ìƒì„±
        5. Train/Val ë¶„í• 
        
        Args:
            df: ì „ì²˜ë¦¬ëœ DataFrame
            validation_split: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
            
        Returns:
            X_train, y_train, X_val, y_val
        """
        print("\n" + "="*60)
        print("ğŸ“Š ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± ì‹œì‘")
        print("="*60)
        
        # 1. Feature ì„ íƒ
        if self.feature_columns is None:
            # ë‚ ì§œ, ì‹¬ë³¼ ì œì™¸í•œ ëª¨ë“  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼
            exclude = ['Date', 'Symbol']
            self.feature_columns = [
                col for col in df.columns 
                if col not in exclude
            ]
        
        print(f"\nğŸ“Œ ì‚¬ìš©í•  Features: {len(self.feature_columns)}ê°œ")
        print(f"   - {', '.join(self.feature_columns[:5])}...")
        
        # 2. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        df_features = df[self.feature_columns].copy()
        
        # 3. ê²°ì¸¡ì¹˜ ì œê±°
        print(f"\nğŸ§¹ ê²°ì¸¡ì¹˜ ì²˜ë¦¬:")
        print(f"   ì²˜ë¦¬ ì „: {df_features.shape}")
        df_features = df_features.dropna()
        print(f"   ì²˜ë¦¬ í›„: {df_features.shape}")
        
        if len(df_features) < self.sequence_length + 1:
            raise ValueError(
                f"ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤! "
                f"ìµœì†Œ {self.sequence_length + 1}í–‰ í•„ìš”"
            )
        
        # 4. ì •ê·œí™” (0~1 ë²”ìœ„)
        print(f"\nğŸ“ ë°ì´í„° ì •ê·œí™” (MinMaxScaler):")
        print(f"   ì˜ˆ: Close {df_features['Close'].min():.2f}~{df_features['Close'].max():.2f}")
        
        scaled_data = self.scaler.fit_transform(df_features)
        
        print(f"   â†’ 0~1 ë²”ìœ„ë¡œ ë³€í™˜")
        
        # 5. ì‹œí€€ìŠ¤ ìƒì„±
        X, y = self._create_sequences(scaled_data, df_features)
        
        print(f"\nğŸ”¢ ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ:")
        print(f"   X shape: {X.shape} (ìƒ˜í”Œ, íƒ€ì„ìŠ¤í…, Features)")
        print(f"   y shape: {y.shape} (ìƒ˜í”Œ,)")
        
        # 6. Train/Val ë¶„í•  (ì‹œê³„ì—´ì€ ìˆœì„œ ìœ ì§€!)
        split_idx = int(len(X) * (1 - validation_split))
        
        X_train = X[:split_idx]
        y_train = y[:split_idx]
        X_val = X[split_idx:]
        y_val = y[split_idx:]
        
        print(f"\nâœ‚ï¸  Train/Val ë¶„í• :")
        print(f"   Train: {X_train.shape[0]} ìƒ˜í”Œ")
        print(f"   Val:   {X_val.shape[0]} ìƒ˜í”Œ")
        
        print("\n" + "="*60)
        print("âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
        print("="*60)
        
        return X_train, y_train, X_val, y_val
    
    def _create_sequences(
        self,
        data: np.ndarray,
        df_original: pd.DataFrame
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Sliding Windowë¡œ ì‹œí€€ìŠ¤ ìƒì„±
        
        ì˜ˆì‹œ (sequence_length=3):
        ë°ì´í„°: [1, 2, 3, 4, 5]
        
        Seq 1: [1, 2, 3] â†’ 4
        Seq 2: [2, 3, 4] â†’ 5
        
        ë”¥ëŸ¬ë‹ ê´€ì :
        - ë” ê¸´ sequence_length = ë” ë§ì€ ê³¼ê±° ì •ë³´
        - í•˜ì§€ë§Œ ë„ˆë¬´ ê¸¸ë©´: í•™ìŠµ ëŠë¦¼, ê¸°ìš¸ê¸° ì†Œì‹¤ ìœ„í—˜
        - ë³´í†µ 30~60ì¼ì´ ì ì ˆ
        """
        X = []  # ì…ë ¥ ì‹œí€€ìŠ¤
        y = []  # íƒ€ê²Ÿ (ë‹¤ìŒ ë‚  ì¢…ê°€)
        
        # Close ì»¬ëŸ¼ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
        target_idx = list(df_original.columns).index(self.target_column)
        
        for i in range(len(data) - self.sequence_length):
            # ì…ë ¥: iì¼ ~ i+sequence_lengthì¼
            X.append(data[i:i + self.sequence_length])
            
            # íƒ€ê²Ÿ: i+sequence_lengthì¼ì˜ ì¢…ê°€
            y.append(data[i + self.sequence_length, target_idx])
        
        return np.array(X), np.array(y)
    
    def save_scaler(self, filepath: str = "data/models/scaler.pkl"):
        """
        ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        
        í˜‘ì—… ì¤‘ìš”!
        - í•™ìŠµ ì‹œ: ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        - ì˜ˆì¸¡ ì‹œ: ê°™ì€ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ë³€í™˜ í•„ìˆ˜!
        - ì•ˆ ê·¸ëŸ¬ë©´ ì˜ˆì¸¡ ê°’ì´ ì´ìƒí•´ì§
        
        ë°±ì—”ë“œ ì—°ë™:
        - APIì—ì„œ ì´ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œí•´ì„œ ì‹¤ì‹œê°„ ë°ì´í„° ë³€í™˜
        """
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'wb') as f:
            pickle.dump(self.scaler, f)
        print(f"ğŸ’¾ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥: {filepath}")
    
    def load_scaler(self, filepath: str = "data/models/scaler.pkl"):
        """ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        with open(filepath, 'rb') as f:
            self.scaler = pickle.load(f)
        print(f"ğŸ“‚ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ: {filepath}")
    
    def inverse_transform_prediction(self, pred: np.ndarray) -> np.ndarray:
        """
        ì •ê·œí™”ëœ ì˜ˆì¸¡ê°’ì„ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³µì›
        
        ì¤‘ìš”!
        - LSTM ì¶œë ¥: 0~1 ë²”ìœ„
        - ì‹¤ì œ ê°€ê²©ìœ¼ë¡œ ë³€í™˜ í•„ìš”
        
        ì˜ˆ: 0.75 â†’ $182.50
        """
        # predê°€ 1Dë©´ 2Dë¡œ ë³€í™˜
        if pred.ndim == 1:
            pred = pred.reshape(-1, 1)
        
        # ì „ì²´ Feature ê°œìˆ˜ë§Œí¼ ë”ë¯¸ ì»¬ëŸ¼ ìƒì„±
        dummy = np.zeros((len(pred), len(self.feature_columns)))
        
        # Close ì»¬ëŸ¼ ìœ„ì¹˜ì— ì˜ˆì¸¡ê°’ ë„£ê¸°
        target_idx = self.feature_columns.index(self.target_column)
        dummy[:, target_idx] = pred.flatten()
        
        # ì—­ë³€í™˜
        inversed = self.scaler.inverse_transform(dummy)
        
        # Close ì»¬ëŸ¼ë§Œ ë°˜í™˜
        return inversed[:, target_idx]

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import pandas as pd
    
    print("ğŸš€ í”„ë¡œê·¸ë¨ ì‹œì‘!")
    
    # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
    data_path = "data/processed/aapl_with_indicators.csv"
    
    if not os.path.exists(data_path):
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {data_path}")
        exit(1)
    
    df = pd.read_csv(data_path)
    print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ: {data_path}")
    print(f"   í¬ê¸°: {df.shape}")
    
    print("\nğŸ”§ SequenceGenerator ìƒì„± ì¤‘...")
    
    # ì‹œí€€ìŠ¤ ìƒì„±
    generator = SequenceGenerator(
        sequence_length=60,
        target_column='Close'
    )
    
    print("âœ… Generator ìƒì„± ì™„ë£Œ")
    print("\nğŸ“Š prepare_data ì‹¤í–‰ ì¤‘...")
    
    try:
        X_train, y_train, X_val, y_val = generator.prepare_data(
            df,
            validation_split=0.2
        )
        
        print("\nâœ… prepare_data ì™„ë£Œ!")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        generator.save_scaler()
        
        # ê²°ê³¼ í™•ì¸
        print(f"\nğŸ“Š ìµœì¢… ë°ì´í„° shape:")
        print(f"   X_train: {X_train.shape}")
        print(f"   y_train: {y_train.shape}")
        print(f"   X_val: {X_val.shape}")
        print(f"   y_val: {y_val.shape}")
        
        print(f"\nğŸ‰ ì‹œí€€ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ:")
        print(f"   {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc() 
